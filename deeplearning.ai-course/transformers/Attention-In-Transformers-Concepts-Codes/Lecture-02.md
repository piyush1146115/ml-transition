# The Matrix Math for Calculating Self-Attention

Attention(Q,K,V)=SoftMax(QK^T/âˆšdk)
q=query
k=key
v= value

- Dot Products can be used as an unscaled measure of similarity between two things, and this metric is closely related to something called the Cosine Similarity. The big difference is that the Cosine Similarity scales the Dot Product to be between -1 and 1
- 
- 